{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger, i'll use one logger for this script\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.DEBUG)\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "file_handler = logging.FileHandler('logs.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stdout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the goal is to scrape all movie ids. but all movies page has 660k entries\n",
    "# clicking a button for 13000 times is not reliable so we need to scrape movies\n",
    "# in batches. we can use various filtering options.\n",
    "# filtering options:\n",
    "# - year\n",
    "# - imdb rating\n",
    "\n",
    "imdb_link = \"https://www.imdb.com/search/title/?title_type=feature\"\n",
    "\n",
    "increment = 0.1\n",
    "imdb_links = []\n",
    "for i in range(1, 10):\n",
    "    for j in range(5):\n",
    "        jj = j / 5\n",
    "        imdb_links.append(\n",
    "            \"https://www.imdb.com/search/title/?title_type=feature&user_rating=\" +\n",
    "            str(round(i + jj, 1)) + \",\" + str(round(i + jj + increment, 1))\n",
    "        )\n",
    "# there actually are movies with 10 ratings\n",
    "imdb_links.append(\"https://www.imdb.com/search/title/?title_type=feature&user_rating=10,\")\n",
    "\n",
    "#print(imdb_links)\n",
    "#for link in imdb_links:\n",
    "#    print(link)\n",
    "\n",
    "# i shouldnt be doing imdb ratings because ratings can change while the scraping is happening\n",
    "# i need to do this with dates. which would be a lot better because that way updating the\n",
    "# database is just a breeze\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "current_date = date.today()\n",
    "y, m, d = str(current_date).split(\"-\")\n",
    "y = int(y)\n",
    "m = int(m)\n",
    "d = int(d)\n",
    "\n",
    "# do the thing in one month periods\n",
    "# 02-01 to 01-02\n",
    "# 02-02 to 01-03\n",
    "# 02-03 to 01-04\n",
    "# ...\n",
    "# 02-11 to 01-12\n",
    "# 02-12 to 01-01-nextyear\n",
    "\n",
    "imdb_links_2 = []\n",
    "\n",
    "# spaghetti code\n",
    "\n",
    "def generate_imdb_links_by_release_dates(date_range):\n",
    "    links = []\n",
    "    for year in range(date_range[0], date_range[1]):\n",
    "        for i in range(12):\n",
    "            from_day = 2\n",
    "            from_month = i + 1\n",
    "            from_year = year\n",
    "\n",
    "            to_day = 1\n",
    "            to_month = i + 2\n",
    "            to_year = year\n",
    "\n",
    "            if to_month == m and to_year == y:\n",
    "                to_day = d\n",
    "\n",
    "            if to_month == 13:\n",
    "                to_month = 1\n",
    "                to_year += 1\n",
    "\n",
    "            #print(f\"{from_day:02d}-{from_month:02d}-{from_year} to {to_day:02d}-{to_month:02d}-{to_year}\")\n",
    "            links.append(f\"https://www.imdb.com/search/title/?title_type=feature&release_date={from_year}-{from_month:02d}-{from_day:02d},{to_year}-{to_month:02d}-{to_day:02d}\")\n",
    "\n",
    "            if to_month == m and to_year == y:\n",
    "                break\n",
    "    return links\n",
    "\n",
    "imdb_links_2 = generate_imdb_links_by_release_dates([2020, 2025])\n",
    "\n",
    "#for link in imdb_links_2:\n",
    "#    print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init browser\n",
    "\n",
    "from math import ceil\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import time \n",
    "  \n",
    "from selenium.webdriver.common.keys import Keys \n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_ids_from_link(browser, link):\n",
    "    browser.get(link)\n",
    "\n",
    "    browser.implicitly_wait(10)\n",
    "\n",
    "    # get the total number of movies from the page\n",
    "    try:\n",
    "        element = browser.find_element(By.CLASS_NAME, \"ipc-page-grid\").find_elements(By.CLASS_NAME, \"ipc-page-grid__item\")[1]\n",
    "    except Exception as e:\n",
    "        logger.info(\"there are no movies. maybe??\")\n",
    "        #logger.exception(e)\n",
    "        #logger.info(\"EXITING\")\n",
    "        #exit(1)\n",
    "        return -1\n",
    "\n",
    "\n",
    "    number_of_movies_str = element.text.split(\"\\n\")[0].split(\" \")[2].replace(\",\", \"\")\n",
    "    #print(number_of_movies_str)\n",
    "    number_of_movies = int(number_of_movies_str)\n",
    "    #print(number_of_movies)\n",
    "\n",
    "    # on one click, the page loads 50 more movies\n",
    "    number_of_max_clicks = ceil(number_of_movies / 50) - 1\n",
    "\n",
    "    print(\"there are \" + number_of_movies_str + \" movies. we need to click \" + str(number_of_max_clicks) + \" in total. haha\")\n",
    "\n",
    "\n",
    "    # click until we load all the movies\n",
    "    # TODO: implement falllbacks on possible errors.\n",
    "    # TODO: implement sanity check while clicking buttons.\n",
    "\n",
    "    # b is the \"see more\" button at the bottom of the page\n",
    "    b = browser.find_elements(By.CLASS_NAME, \"ipc-see-more\")\n",
    "    #print(b)\n",
    "    for i in range(number_of_max_clicks):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        time.sleep(2)\n",
    "        while True:\n",
    "            try:\n",
    "                b[0].click()\n",
    "                break\n",
    "            except:\n",
    "                logger.error(\"something bad happened while clicking. trying again\")\n",
    "                browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "                time.sleep(2)\n",
    "\n",
    "        time.sleep(2)\n",
    "        #print(\"[LOG] \" + str(i) + \" out of \" + str(number_of_max_clicks) + \" completed. %\" + str(i / number_of_max_clicks))\n",
    "        logger.info(str(i + 1) + \" out of \" + str(number_of_max_clicks) + \" completed. %\" + str((i + 1) / number_of_max_clicks * 100))\n",
    "\n",
    "    logger.info(\"done. maybe??\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-09 16:35:52,474 | INFO | START[1/49]! attemting to scrape links for date [2020-01-02,2020-02-01]\n",
      "2024-02-09 16:35:52,474 | INFO | START[1/49]! attemting to scrape links for date [2020-01-02,2020-02-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1399 movies. we need to click 27 in total. haha\n",
      "2024-02-09 16:36:02,591 | INFO | 1 out of 27 completed. %3.7037037037037033\n",
      "2024-02-09 16:36:02,591 | INFO | 1 out of 27 completed. %3.7037037037037033\n",
      "2024-02-09 16:36:06,843 | INFO | 2 out of 27 completed. %7.4074074074074066\n",
      "2024-02-09 16:36:06,843 | INFO | 2 out of 27 completed. %7.4074074074074066\n",
      "2024-02-09 16:36:10,964 | INFO | 3 out of 27 completed. %11.11111111111111\n",
      "2024-02-09 16:36:10,964 | INFO | 3 out of 27 completed. %11.11111111111111\n",
      "2024-02-09 16:36:15,148 | INFO | 4 out of 27 completed. %14.814814814814813\n",
      "2024-02-09 16:36:15,148 | INFO | 4 out of 27 completed. %14.814814814814813\n",
      "2024-02-09 16:36:19,471 | INFO | 5 out of 27 completed. %18.51851851851852\n",
      "2024-02-09 16:36:19,471 | INFO | 5 out of 27 completed. %18.51851851851852\n",
      "2024-02-09 16:36:23,937 | INFO | 6 out of 27 completed. %22.22222222222222\n",
      "2024-02-09 16:36:23,937 | INFO | 6 out of 27 completed. %22.22222222222222\n",
      "2024-02-09 16:36:28,283 | INFO | 7 out of 27 completed. %25.925925925925924\n",
      "2024-02-09 16:36:28,283 | INFO | 7 out of 27 completed. %25.925925925925924\n",
      "2024-02-09 16:36:31,377 | ERROR | something bad happened while clicking. trying again\n",
      "2024-02-09 16:36:31,377 | ERROR | something bad happened while clicking. trying again\n",
      "2024-02-09 16:36:35,717 | INFO | 8 out of 27 completed. %29.629629629629626\n",
      "2024-02-09 16:36:35,717 | INFO | 8 out of 27 completed. %29.629629629629626\n",
      "2024-02-09 16:36:40,195 | INFO | 9 out of 27 completed. %33.33333333333333\n",
      "2024-02-09 16:36:40,195 | INFO | 9 out of 27 completed. %33.33333333333333\n",
      "2024-02-09 16:36:44,462 | INFO | 10 out of 27 completed. %37.03703703703704\n",
      "2024-02-09 16:36:44,462 | INFO | 10 out of 27 completed. %37.03703703703704\n",
      "2024-02-09 16:36:49,032 | INFO | 11 out of 27 completed. %40.74074074074074\n",
      "2024-02-09 16:36:49,032 | INFO | 11 out of 27 completed. %40.74074074074074\n",
      "2024-02-09 16:36:53,656 | INFO | 12 out of 27 completed. %44.44444444444444\n",
      "2024-02-09 16:36:53,656 | INFO | 12 out of 27 completed. %44.44444444444444\n",
      "2024-02-09 16:36:58,331 | INFO | 13 out of 27 completed. %48.148148148148145\n",
      "2024-02-09 16:36:58,331 | INFO | 13 out of 27 completed. %48.148148148148145\n",
      "2024-02-09 16:37:03,172 | INFO | 14 out of 27 completed. %51.85185185185185\n",
      "2024-02-09 16:37:03,172 | INFO | 14 out of 27 completed. %51.85185185185185\n",
      "2024-02-09 16:37:07,978 | INFO | 15 out of 27 completed. %55.55555555555556\n",
      "2024-02-09 16:37:07,978 | INFO | 15 out of 27 completed. %55.55555555555556\n",
      "2024-02-09 16:37:13,057 | INFO | 16 out of 27 completed. %59.25925925925925\n",
      "2024-02-09 16:37:13,057 | INFO | 16 out of 27 completed. %59.25925925925925\n",
      "2024-02-09 16:37:17,662 | INFO | 17 out of 27 completed. %62.96296296296296\n",
      "2024-02-09 16:37:17,662 | INFO | 17 out of 27 completed. %62.96296296296296\n",
      "2024-02-09 16:37:22,531 | INFO | 18 out of 27 completed. %66.66666666666666\n",
      "2024-02-09 16:37:22,531 | INFO | 18 out of 27 completed. %66.66666666666666\n",
      "2024-02-09 16:37:27,891 | INFO | 19 out of 27 completed. %70.37037037037037\n",
      "2024-02-09 16:37:27,891 | INFO | 19 out of 27 completed. %70.37037037037037\n",
      "2024-02-09 16:37:33,346 | INFO | 20 out of 27 completed. %74.07407407407408\n",
      "2024-02-09 16:37:33,346 | INFO | 20 out of 27 completed. %74.07407407407408\n",
      "2024-02-09 16:37:38,989 | INFO | 21 out of 27 completed. %77.77777777777779\n",
      "2024-02-09 16:37:38,989 | INFO | 21 out of 27 completed. %77.77777777777779\n",
      "2024-02-09 16:37:44,271 | INFO | 22 out of 27 completed. %81.48148148148148\n",
      "2024-02-09 16:37:44,271 | INFO | 22 out of 27 completed. %81.48148148148148\n",
      "2024-02-09 16:37:49,546 | INFO | 23 out of 27 completed. %85.18518518518519\n",
      "2024-02-09 16:37:49,546 | INFO | 23 out of 27 completed. %85.18518518518519\n",
      "2024-02-09 16:37:54,693 | INFO | 24 out of 27 completed. %88.88888888888889\n",
      "2024-02-09 16:37:54,693 | INFO | 24 out of 27 completed. %88.88888888888889\n",
      "2024-02-09 16:37:59,917 | INFO | 25 out of 27 completed. %92.5925925925926\n",
      "2024-02-09 16:37:59,917 | INFO | 25 out of 27 completed. %92.5925925925926\n",
      "2024-02-09 16:38:05,546 | INFO | 26 out of 27 completed. %96.29629629629629\n",
      "2024-02-09 16:38:05,546 | INFO | 26 out of 27 completed. %96.29629629629629\n",
      "2024-02-09 16:38:11,065 | INFO | 27 out of 27 completed. %100.0\n",
      "2024-02-09 16:38:11,065 | INFO | 27 out of 27 completed. %100.0\n",
      "2024-02-09 16:38:11,068 | INFO | done. maybe??\n",
      "2024-02-09 16:38:11,068 | INFO | done. maybe??\n",
      "2024-02-09 16:38:11,072 | INFO | clicking completed.\n",
      "2024-02-09 16:38:11,072 | INFO | clicking completed.\n",
      "2024-02-09 16:38:11,076 | INFO | getting all the links and saving them to a file\n",
      "2024-02-09 16:38:11,076 | INFO | getting all the links and saving them to a file\n",
      "2024-02-09 16:38:24,226 | INFO | saved links to file.\n",
      "2024-02-09 16:38:24,226 | INFO | saved links to file.\n",
      "2024-02-09 16:38:24,230 | INFO | START[2/49]! attemting to scrape links for date [2020-02-02,2020-03-01]\n",
      "2024-02-09 16:38:24,230 | INFO | START[2/49]! attemting to scrape links for date [2020-02-02,2020-03-01]\n",
      "there are 1254 movies. we need to click 25 in total. haha\n",
      "2024-02-09 16:38:35,586 | INFO | 1 out of 25 completed. %4.0\n",
      "2024-02-09 16:38:35,586 | INFO | 1 out of 25 completed. %4.0\n",
      "2024-02-09 16:38:39,764 | INFO | 2 out of 25 completed. %8.0\n",
      "2024-02-09 16:38:39,764 | INFO | 2 out of 25 completed. %8.0\n",
      "2024-02-09 16:38:41,775 | ERROR | failed to scrape links for date [2020-02-02,2020-03-01]. trying again\n",
      "2024-02-09 16:38:41,775 | ERROR | failed to scrape links for date [2020-02-02,2020-03-01]. trying again\n",
      "there are 1254 movies. we need to click 25 in total. haha\n",
      "2024-02-09 16:38:50,503 | INFO | 1 out of 25 completed. %4.0\n",
      "2024-02-09 16:38:50,503 | INFO | 1 out of 25 completed. %4.0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "final_links = imdb_links_2\n",
    "\n",
    "for link in final_links:\n",
    "    i += 1\n",
    "    link_date = link.split(\"release_date=\")[1]\n",
    "    links_file = open(f\"./imdb_ids/{link_date}.txt\", \"w\")\n",
    "    \n",
    "    logger.info(f\"START[{i}/{len(final_links)}]! attemting to scrape links for date [{link_date}]\")\n",
    "\n",
    "    ret = 0\n",
    "    while True:\n",
    "        try:\n",
    "            ret = scrape_ids_from_link(browser, link)\n",
    "            if ret == 0:\n",
    "                logger.info(\"clicking completed.\")\n",
    "            break\n",
    "        except:\n",
    "            logger.error(f\"failed to scrape links for date [{link_date}]. trying again\")\n",
    "            pass\n",
    "        \n",
    "\n",
    "    # get all ids from the webpage\n",
    "    # TODO: remember implementing sanity checks\n",
    "\n",
    "    # im just assuming this works here\n",
    "    if ret == 0:\n",
    "        logger.info(\"getting all the links and saving them to a file\")\n",
    "        for elem in browser.find_elements(By.CLASS_NAME, \"ipc-title-link-wrapper\"):\n",
    "            links_file.write(elem.get_attribute(\"href\"))\n",
    "            links_file.write(\"\\n\")\n",
    "        logger.info(\"saved links to file.\")\n",
    "    else:\n",
    "        logger.info(\"no links found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
